<!--
 * Copyright (c) 2023 by Huanxuan Liao, huanxuanliao@gmail.com, All Rights Reserved. 
 * @Author: Xnhyacinth, Xnhyacinth@qq.com
 * @Date: 2023-11-26 16:25:40
-->
# Language Model
Comparison of perplexity in language models utilizing feedforward neural networks, recurrent neural networks, and self-attention mechanism networks.

data: [https://data.statmt.org/news-crawl/zh/](https://data.statmt.org/news-crawl/zh/), the last 1000 sentences are designated as the validation set, while the remainder serves as the training set.
## ğŸ“ Folder

```bash
â”œâ”€â”€data # train.txt test.txt
â”œâ”€â”€scripts # some scripts for examples
â”œâ”€â”€data.py # process data
â”œâ”€â”€get_data.py # split data
â”œâ”€â”€FNN_LM.py # FFN for LM
â”œâ”€â”€LM.py # RNN & LSTM & SAS for LM
â”œâ”€â”€utils.py # Logging
```